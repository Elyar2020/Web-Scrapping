{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSpphe9veczB"
   },
   "source": [
    "# â›³ Web Scraping Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAwdyQbCfiP2"
   },
   "source": [
    "# **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "10IlJ0bLfj82"
   },
   "outputs": [],
   "source": [
    "import requests # for getting web contents\n",
    "from bs4 import BeautifulSoup # for scraping web contents\n",
    "import pandas as pd # for data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKd7z5Fmf3bP"
   },
   "source": [
    "# **â›³ URL**\n",
    "***For web scrapping it's important to have url.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ldPAy2dGf_PL"
   },
   "outputs": [],
   "source": [
    "# link of web page that you want to scrap data\n",
    "URL = ''\n",
    "\n",
    "# get web data\n",
    "page = requests.get(URL)\n",
    "\n",
    "# parse web data\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gb-ZVpxZhv7X"
   },
   "outputs": [],
   "source": [
    "# find the table\n",
    "# our trageted table is last\n",
    "\n",
    "# getting the table head because it may contains headings (column names)\n",
    "html_thead = soup.find_all('thead')[-1]\n",
    "\n",
    "#getting all the rows in table head\n",
    "html_tr = [tr for tr in html_thead.find_all('tr')]\n",
    "\n",
    "# list to store all table headings\n",
    "headings = []\n",
    "\n",
    "# loop through table head\n",
    "for tr in html_tr:\n",
    "    # getting all th\n",
    "    th = tr.find_all(['th'])\n",
    "    # storing all th value in row and removing white space\n",
    "    row = [i.text.strip() for i in th]\n",
    "    # append headings \n",
    "    headings.append(row)\n",
    "    \n",
    "# print heading\n",
    "print(headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCCG3Ihnhh5Y"
   },
   "outputs": [],
   "source": [
    "# getting the table body\n",
    "html_tbody = soup.find_all('tbody')[-1]\n",
    "\n",
    "#getting all the rows in table body\n",
    "html_text = [tr for tr in html_tbody.find_all('tr')]\n",
    "\n",
    "# list to store all content\n",
    "content = []\n",
    "\n",
    "# loop through table body\n",
    "for tr in html_text:\n",
    "    # getting all th, td\n",
    "    th = tr.find_all(['th','td'])\n",
    "    # storing all th value in row and removing white space\n",
    "    row = [i.text.strip() for i in th]\n",
    "    # append content \n",
    "    content.append(row)\n",
    "    \n",
    "# print content\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIQt3zFJfnIM"
   },
   "outputs": [],
   "source": [
    "# save contents in a dataframe\n",
    "data = pd.DataFrame(content[:], columns=headings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15bD9zAJh_Yz"
   },
   "source": [
    "# **Data Analysis**\n",
    "\n",
    "**Look at Example Records**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LujGUKXDiGzQ"
   },
   "outputs": [],
   "source": [
    "# check few top rows of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UN0ztjXiXsx"
   },
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUD-RQ4CiY69"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i25nAobwifb6"
   },
   "source": [
    "# **Data Cleaning**\n",
    "\n",
    "**Rename Column Name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDA_gkWeiihB"
   },
   "outputs": [],
   "source": [
    "# rename column name if required\n",
    "data = data.rename(columns={'First Column Name':'New Name', 'Second Column Name':'New Name'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayVjt1cPisav"
   },
   "source": [
    "# Remove unwanted symbols (like % and thousand comma from integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ia9T807qivi7"
   },
   "outputs": [],
   "source": [
    "# remove extra characters from columns\n",
    "data['column name'] = data['column name'].str.replace('%','')\n",
    "data['column name'] = data['column name'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNleJq9Ji4gZ"
   },
   "source": [
    "# **Save Data into CSV**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02-bWKpti78k"
   },
   "outputs": [],
   "source": [
    "# save data\n",
    "data.to_csv('fileName.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-k215M5iXWy"
   },
   "outputs": [],
   "source": [
    "This template helps you to scrap data from any website and convert data to CSV file\n",
    "and once you have CSV file save file in your local\n",
    "directry or cloud and  than you can do data cleaning or Analysing same as any CSV files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uejjg8B3jrmk"
   },
   "source": [
    "**This template helps you to scrap data from any website and convert data to CSV file**\n",
    "\n",
    "**And once you have CSV file save file in your local**\n",
    "\n",
    "\n",
    "**directry or cloud and  than you can do data cleaning** \n",
    "\n",
    "**or Analysing same as any CSV files. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dJJ9FbVkAL7"
   },
   "source": [
    "# Good Luck eveybody!!!! ðŸ™‚\n",
    "\n",
    "**Please let me know if you like this templates or not. **"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Web Scraping Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
